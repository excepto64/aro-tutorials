{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse kinematics\n",
    "This notebook considers the problem of inverse kinematics, ie solving at each control cycle of the robot a quadratic program from the derivatives (jacobian) of the current state. It introduces the basic function to compute the Jacobians of the robot, and how to use them to compute an inverse-kinematics control law. One of the key difficulties is to understand in which frames each quantities is computed (this might be in the world frame, in the local frame attached to the end-effector, in some arbitrary goal frame, etc), as we should never mix quantities expressed in different frames. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: as for all the tutorials, a magic command %do_not_load is introduced to hide the solutions to some questions. Change it for %load if you want to see (and execute) the solution.\n"
     ]
    }
   ],
   "source": [
    "import magic_donotload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "Let us import the standard libraries for the tutorials and load a new robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/inverse_kinematics_import\n",
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "import time\n",
    "from numpy.linalg import pinv,inv,norm,svd,eig\n",
    "from tp3.tiago_loader import loadTiago\n",
    "import matplotlib.pylab as plt\n",
    "from utils.meshcat_viewer_wrapper import MeshcatVisualizer, planar\n",
    "import unittest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Tiago robot (https://youtu.be/6BwRqwD066g). This mobile manipulator from PAL Robotics as a mobile basis which can move in the plane (3 degrees of freedom or dof), a manipulator arm (7 dof) and a head (2 dof) both mounted on a prismatic axis moving vertically (1 dof). This makes 3 dof for the basis, and 9 dof for the body. It also has 2 extra joints tot figure the wheels, which are not very useful for this notebook. The wheels and the basis rotations are represented by the cos and sin of the angle. The size of the configuration vector is then 18, while the velocity vector has dimension 15.\n",
    "\n",
    "A load function is available to make it easy to load the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:76: UserWarning: Deprecated member. Use Frame.parentJoint instead.\n",
      "  JIDX = robot.model.frames[FIDX].parent\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:81: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axis_x',FIDX,JIDX,cyl,pin.SE3(X,X@med+eff)))\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:84: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axis_y',FIDX,JIDX,cyl,pin.SE3(Y,Y@med+eff)))\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:87: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axis_z',FIDX,JIDX,cyl,pin.SE3(Z,Z@med+eff)))\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:94: UserWarning: Deprecated member. Use Frame.parentJoint instead.\n",
      "  JIDX = robot.model.frames[FIDX].parent\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:99: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axis2_x',FIDX,JIDX,cyl,pin.SE3(X,X@med+eff)))\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:102: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axi2_y',FIDX,JIDX,cyl,pin.SE3(Y,Y@med+eff)))\n",
      "/home/ah/ARO/aro-tutorials/tp3/tiago_loader.py:105: UserWarning: This function has been marked as deprecated and will be removed in a future release.\n",
      "  geom.addGeometryObject(pin.GeometryObject('axis2_z',FIDX,JIDX,cyl,pin.SE3(Z,Z@med+eff)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7002/static/\n"
     ]
    }
   ],
   "source": [
    "# %load tp3/generated/inverse_kinematics_robot\n",
    "robot = loadTiago()\n",
    "viz = MeshcatVisualizer(robot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7002/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration is represented by a vector of larger dimension, subject to constraints (cos^2+sin^2=1). It is not possible to randomly sample a configuration vector q, as these constraints should be respected. Similarly, we should take care when integrating a velocity as summing a configuration q with a velocity v will not work (dimensions do not match). Two functions in Pinocchio implements these functionnalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pin.randomConfiguration(robot.model)\n",
    "vq = np.random.rand(robot.model.nv)*2-1\n",
    "DT = 1e-2\n",
    "qnext = pin.integrate(robot.model,q,vq*DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example moving the robot in the viewer following a constant (random) velocity is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in range(1000):\n",
    "#     q = pin.integrate(robot.model,q,vq*DT)\n",
    "#     viz.display(q)\n",
    "#     time.sleep(DT/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.display(robot.q0)\n",
    "q = robot.q0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robot is mobile, hence the camera view in the viewer is not always centered. You can also see here that respecting joint limits might be a good idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward kinematics and Jacobian\n",
    "We recall first the basic method to compute the robot forward kinematics.\n",
    "We will consider two frames of interest on the robot: the first one, named `tool` is at the tip of the end-effector ; the second one, named `basis`, is on the front of the robot basis, 10 cm above the ground. Both are represented in meshcat by a frame composed of three RGB arrows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/inverse_kinematics_frames\n",
    "IDX_TOOL = robot.model.getFrameId('frametool')\n",
    "IDX_BASIS = robot.model.getFrameId('framebasis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frame name: frametool paired to (parent joint/ parent frame)(9/52)\n",
       "with relative placement wrt parent joint:\n",
       "  R =\n",
       "1 0 0\n",
       "0 1 0\n",
       "0 0 1\n",
       "  p =    0    0 0.08\n",
       "containing inertia:\n",
       "  m = 0\n",
       "  c = 0 0 0\n",
       "  I = \n",
       "0 0 0\n",
       "0 0 0\n",
       "0 0 0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.model.frames[IDX_TOOL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing frame placement\n",
    "These frames are computed by the Pinocchio function framesForwardKinematics, whose results are stored in robot.data.oMf.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool placement:   R =\n",
      "           1  4.89675e-12  9.79328e-12\n",
      " 9.79317e-12 -9.79328e-12           -1\n",
      "-4.89653e-12            1 -9.79317e-12\n",
      "  p = 1.10805  0.1855  0.7065\n",
      "\n",
      "Basis placement:   R =\n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "  p =  1.3    1 0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "print(\"Tool placement:\",robot.data.oMf[IDX_TOOL])\n",
    "print(\"Basis placement:\",robot.data.oMf[IDX_BASIS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.addSphere('effector',0.1,[0,0,1,1]) #effector in blue\n",
    "viz.applyConfiguration('effector', [1.1,0.2,0.7,1,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to notice the instruction pattern (which is standard in all Pinocchio functions): first call a whole-body algorithm (here *pin.framesForwardKinematics*), then access the results into *robot.data*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool-placement matrix oMtool represents the displacement from the world frame F_o to the tool frame F_tool. It is composed on a rotation matrix oRtool and a 3D vector o_OT: oMf = [ oRf o_OT ], when o_OT is the vector from the origin of frame F_o to the origin of from F_tool ; this vector is expressed in the world frame F_o. We can instead express OT in the tool frame F_tool by multiplying it by oRtool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  R =\n",
      "           1  4.89675e-12  9.79328e-12\n",
      " 9.79317e-12 -9.79328e-12           -1\n",
      "-4.89653e-12            1 -9.79317e-12\n",
      "  p = 1.10805  0.1855  0.7065\n",
      "\n",
      "[[ 1.00000000e+00  4.89674967e-12  9.79327730e-12]\n",
      " [ 9.79316628e-12 -9.79327730e-12 -1.00000000e+00]\n",
      " [-4.89652763e-12  1.00000000e+00 -9.79316628e-12]] [1.10805 0.1855  0.7065 ]\n",
      "[ 1.10805  0.7065  -0.1855 ]\n"
     ]
    }
   ],
   "source": [
    "# Displacement from the world frame to the tool frame\n",
    "oMtool = robot.data.oMf[IDX_TOOL]\n",
    "print(oMtool)\n",
    "# Rotation and  vector from f_o to f_tool\n",
    "oRtool = oMtool.rotation; o_OT = oMtool.translation\n",
    "print(oRtool, o_OT)\n",
    "tool_OT = oRtool.T @ o_OT\n",
    "print(tool_OT)\n",
    "\n",
    "pos = [0,0,0,1,0,0,0]\n",
    "pos[0:3] = tool_OT\n",
    "\n",
    "viz.applyConfiguration('effector', pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beware of the multiplication operator in numpy. The operator* is (unintuitively) mapped to the coefficient-wise multiplication ... i.e. not at all the matrix multiplication. You should use the operator @ to get the real matrix-matrix product. \n",
    "Never mind, you will likely be tricked at least once by this design pattern. If you don't like it ... well there is nothing to do, this is the basic matrix library in Python, the world most used language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Jacobians\n",
    "The jacobian of a frame of the robot is computed using pin.computeFrameJacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jtool = pin.computeFrameJacobian(robot.model,robot.data,q,IDX_TOOL)\n",
    "Jtool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix has 6 rows and NV=15 columns. It corresponds to the \"spatial\" 6D velocity of the end effector. Let's first focus on the 3 first rows, corresponding to the linear velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  9.79316628e-12,  8.14500000e-01,\n",
       "        -4.89652763e-12,  8.28500000e-01,  7.81041481e-17,\n",
       "        -2.05168521e-12, -1.91950300e-12, -4.44089210e-18,\n",
       "         8.00000000e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.89674967e-12, -9.79327730e-12,  2.93007014e-12,\n",
       "         1.00000000e+00,  3.91005794e-12,  7.03500000e-01,\n",
       "        -8.32410529e-13, -3.92000000e-01, -3.91726651e-13,\n",
       "        -1.91812211e-24,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.79327730e-12, -1.00000000e+00, -1.08050000e-01,\n",
       "        -9.79316628e-12, -1.50000000e-02, -1.83130522e-12,\n",
       "         4.07596736e-24,  2.00000000e-02, -2.96654885e-41,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jtool3 = Jtool[:3,:]\n",
    "Jtool3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian as a velocity operator\n",
    "A first way to understand what is this matrix is to see that as an operator that converts the velocity in the configuration space into the linear velocity of the end effector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37652315, -0.88376652,  0.10525341])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtool = Jtool3 @ vq\n",
    "vtool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in which frame is vtool expressed? The choice in Pinocchio (following algorithmic principles described in [Featherstone 2009]) is to express quantities in the local frame by default. So vtool is expressed in the tool frame F_tool (or more precisely, the Galilean frame coinciding with F_tool at the current time instant). We would better denote it with its frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_Jtool = pin.computeFrameJacobian(robot.model,robot.data,q,IDX_TOOL)\n",
    "tool_Jtool3 = tool_Jtool[:3,:]\n",
    "tool_vtool = tool_Jtool3 @ vq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using long variable names. In the code, these explicit notations are maybe too much. It is your choice to use them or not. \n",
    "The tool velocity is easier to interpret in the world frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37548221, -0.10558064, -0.88417027])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_vtool = oRtool @ tool_vtool\n",
    "o_vtool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generalise this notation to the jacobian expressed in the world frame F_o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999316e-01, -1.70683494e-04,  8.14481000e-01,\n",
       "        -1.15722877e-03,  8.28496873e-01, -8.14110438e-04,\n",
       "        -2.05072052e-12,  4.57047345e-04,  4.48876461e-16,\n",
       "         7.99999453e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.71027767e-04,  9.99999941e-01,  1.08189296e-01,\n",
       "         2.97404889e-04,  1.51416956e-02,  2.09224334e-04,\n",
       "        -5.98458116e-16, -2.01165815e-02, -1.16502177e-16,\n",
       "         1.36822221e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.15717794e-03, -2.97602604e-04,  9.10365473e-04,\n",
       "         9.99999286e-01,  9.54257886e-04,  7.03499498e-01,\n",
       "        -8.34784100e-13, -3.91993768e-01, -3.91726377e-13,\n",
       "         9.25742350e-05,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_Jtool3 = oRtool @ tool_Jtool3\n",
    "o_Jtool3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian as a derivative\n",
    "A second interpretation to explain what is the jacobian is to observe that it is the derivative of the vector o_OT (the tool position in world frame). Indeed o_OT is a function of q: o_OT(q). We can take its derivative with respect to q, denoted d o_OT / dq. This derivative is equal to the Jacobian expressed in the world frame F_o: d o_OT / dq = o_Jtool.\n",
    "To be convinced of that, let's check the finite differences. We take a small movement dq, and see that the change in position o_OT(q+dq) corresponds to the linear prediction o_Jtool3*dq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.10805 0.1855  0.7065 ]\n",
      "[ 0.29989327 -0.92420906  0.73267424]\n",
      "[ 0.29922585 -0.92398266  0.73329616]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "viz.display(robot.q0)\n",
    "time.sleep(0.5)\n",
    "q = robot.q0.copy()\n",
    "\n",
    "# Take small change in configuration\n",
    "# Sample between -0.001 and 0.001\n",
    "EPS = 1e-3\n",
    "dq = (np.random.rand(robot.model.nv)*2-1)*EPS\n",
    "\n",
    "# Apply that change to original configuration\n",
    "# q2 = q+dq\n",
    "q2 = pin.integrate(robot.model,q,dq)\n",
    "viz.display(q2)                     \n",
    "pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "\n",
    "# tool position for q wrt world frame\n",
    "o_OT = robot.data.oMf[IDX_TOOL].translation.copy()\n",
    "print(o_OT)\n",
    "\n",
    "# tool position for q+dq wrt world frame\n",
    "pin.framesForwardKinematics(robot.model,robot.data,q2)\n",
    "o_OT2 = robot.data.oMf[IDX_TOOL].translation.copy()\n",
    "\n",
    "print((o_OT2 - o_OT)/EPS)\n",
    "print((o_Jtool3@dq/EPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frame options in Pinocchio\n",
    "Most algorithms accept an option to specify in wich frame the spatial quantity should be expressed. The two basic options are *pin.LOCAL* and *pin.WORLD*. When related to velocity, *LOCAL* is the linear velocity of the center of the local frame (the TOOL_IDX frame, here) and the angular velocity, both expressed in the local frame. With *WORLD* frame, the two velocities are expressed in the world frame ... but remember that the linear velocity is then difficult to interpret.\n",
    "\n",
    "A last option is given for convenience, which does not respect the mathematics of spatial velocity, but matches the French \"torseur cin√©matique\": pin.LOCAL_WORLD_ALIGNED gives the linear velocity of the center of the local frame and the angular velocity, both expressed in the world frame. It is convenient especially when we are interested in considering the linear velocity as the derivative of the position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_Jtool = pin.computeFrameJacobian(robot.model,robot.data,q,IDX_TOOL,\n",
    "                                   pin.LOCAL_WORLD_ALIGNED)[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can watch this video which explain with more illustrations the 3 frame options:  https://youtu.be/MLFtHLTprE4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jacobian in 6D\n",
    "The jacobian of the frame indeed has 6 rows, and corresponds to the spatial velocity of the frame. It is expressed locally, in the tool frame (or more precisely the Galilean frame coincinding with the tool frame to the current time instant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_J = pin.computeFrameJacobian(robot.model,robot.data,q,IDX_TOOL)\n",
    "tool_nu = tool_J @ vq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote by nu the spatial velocity. It is composed by the linear velocity of the center of the frame vtool and the angular velocity of the tool frame, both expressed in the tool frame: tool_nu = [ tool_vtool, tool_w ].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_vtool = tool_nu[:3] ; tool_w = tool_nu[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead express the spatial velocity in the world frame F_o by multiplying it by the so-called action matrix oXtool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_nu = oMtool.action @ tool_nu\n",
    "print(o_nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log in SE(3)\n",
    "Finally, the log operator transforms a displacement M in SE(3) into the spatial (6D) velocity that should be applied during 1 second to achieve this displacement. The spatial velocity is expressed in the frame at the origin of the displacement (i.e. nu=log(oMtool) is expressed in the world frame F_o). In Pinocchio, the log returns an object of class Motion, that can be converted to a numpy vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_nu = pin.log(oMtool).vector\n",
    "print(o_nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse kinematics for the moving the robot effector\n",
    "We will first move only the robot end effector, to reach a target defined by a frame $F_{goal}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/inverse_kinematics_goal\n",
    "# Goal placement, and integration in the viewer of the goal.\n",
    "oMgoal = pin.SE3(pin.Quaternion(-0.5, 0.58, -0.39, 0.52).normalized().matrix(),\n",
    "                np.array([1.2, .4, .7]))\n",
    "viz.addBox('goal', [.1,.1,.1], [ .1,.1,.5, .6] )\n",
    "viz.applyConfiguration('goal',oMgoal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position the effector (3d)\n",
    "It is time to write your first control law. Write a for-loop to iterate along the control cycles of the robot. At each control cycle, you should:\n",
    "* compute the Jacobian 3D in the world frame o_Jtool3\n",
    "* compute the vector from the tool to the goal, expressed in world frame: o_TG = o_goal - o_tool. Interpret this vector as a velocity command\n",
    "* compute the control law as vq=-pinv(J)*o_TG\n",
    "* integrate the velocity vq during DT to get a new configuration q.\n",
    "You might want to start from the following initial configuration, or from any random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/inverse_kinematics_init\n",
    "# Robot initial configuration.\n",
    "q0 = np.array([ 0.  ,  0.  ,  1.  ,  0.  ,  0.18,  1.37, -0.24, -0.98,  0.98,\n",
    "                0.  ,  0.  ,  0.  ,  0.  , -0.13,  0.  ,  0.  ,  0.  ,  0.  ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good idea to store the values of the error between tool and goal o_TG, to plot them later. For that, simply append each o_TG computed at every control cycle in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load tp3/generated/inverse_kinematics_3d_loop\n",
    "q = q0.copy()\n",
    "herr = [] # Log the value of the error between tool and goal.\n",
    "# Loop on an inverse kinematics for 200 iterations.\n",
    "for i in range(200):  # Integrate over 2 second of robot life\n",
    "\n",
    "    # Run the algorithms that outputs values in robot.data\n",
    "    pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "    pin.computeJointJacobians(robot.model,robot.data,q)\n",
    "    \n",
    "    # Placement from world frame o to frame f oMtool\n",
    "    oMtool = None #TODO\n",
    "    \n",
    "    # 3D jacobian in world frame\n",
    "    o_Jtool3 = None #TODO\n",
    "    \n",
    "    # error vector from tool to goal, in world frame\n",
    "    o_TG = np.zeros(3) #TODO\n",
    "    \n",
    "    # Control law by least square (using the pseudo-inverse method)\n",
    "    vq = np.zeros(robot.nv) #TODO\n",
    "    \n",
    "    q = pin.integrate(robot.model,q, vq * DT)\n",
    "    viz.display(q)\n",
    "    time.sleep(1e-3)\n",
    "\n",
    "    herr.append(o_TG) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to plot the behavior of the robot. If the error at each iteration has been stored as a list of 3x1 matrices, the following code plots it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(herr)\n",
    "plt.xlabel('control cycle (iter)')\n",
    "plt.ylabel('error (m)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that each component of the error converges towards 0 following an exponential trajetory. The convergence is assymptotic. To accelerate the convergence, increase the gain of the control law ($v_q = - \\lambda J^+ e$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place the end effector (6D)\n",
    "The previous control law brings the center of the effector toward the center of the goal frame. However, it does not control the orientation of the end effector: the axes of the two frames F_tool and F_goal do not converge.\n",
    "We should now modify the control law to take into account the tool orientation. For that, we compute the error to be the SE(3) log of the displacement from the tool frame F_tool to the goal frame F_goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolMgoal = oMtool.inverse()*oMgoal\n",
    "tool_nu = pin.log(toolMgoal).vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error tool_nu is a 6d vector, that can be interpreted as the spatial (6d) velocity that should be applied during 1 second to displace the tool frame F_tool (placed at oMtool) to the goal frame F_goal (placed at oMgoal). This spatial velocity is expressed in the tool frame F_tool. It then corresponds to the 6D jacobian, that is also computed in the same frame F_tool.\n",
    "\n",
    "Implement a second control law, following the same pattern than the previous control law. At each control cycle, you should:\n",
    "* compute the displacement between F_tool and F_goal, denoted toolMgoal\n",
    "* compute the 6D error using the SE(3) log tool_nu\n",
    "* compute the 6D jacobian tool_Jtool\n",
    "* compute the control law vq = pinv(J)*nu\n",
    "* integrate the robot velocity vq during DT to get a new configuration q\n",
    "* log the error by storing it in a list herr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oMgoal.actInv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load tp3/generated/inverse_kinematics_6d_loop\n",
    "q = q0.copy()\n",
    "herr = []\n",
    "for i in range(300):  # Integrate over 3 second of robot life\n",
    "\n",
    "    # Run the algorithms that outputs values in robot.data\n",
    "    #TODO\n",
    "\n",
    "    # Placement from world frame o to frame f oMtool  \n",
    "    #TODO\n",
    "\n",
    "    # 6D error between the two frame\n",
    "    #TODO\n",
    "\n",
    "    # Get corresponding jacobian\n",
    "    #TODO\n",
    "\n",
    "    # Control law by least square\n",
    "    vq = np.zeros(robot.nv) #TODO\n",
    "\n",
    "    q = pin.integrate(robot.model,q, vq * DT)\n",
    "    viz.display(q)\n",
    "    time.sleep(1e-3)\n",
    "\n",
    "    herr.append(tool_nu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool frame F_tool converges toward the gooal frame F_goal: the center and the axes are finally aligned. The trajectory of the tool center is not a straight line, as the frame F_tool follows a \"straight\" line, not in R^3 but in SE(3).\n",
    "We can also plot the error (assuming that herr is a list of the 6D errors herr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/inverse_kinematics_plot\n",
    "plt.subplot(211)\n",
    "plt.plot([ e[:3] for e in herr])\n",
    "plt.xlabel('control cycle (iter)')\n",
    "plt.ylabel('error (m)')\n",
    "plt.subplot(212)\n",
    "plt.plot([ e[3:] for e in herr])\n",
    "plt.xlabel('control cycle (iter)')\n",
    "plt.ylabel('error (rad)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse kinematics for two tasks\n",
    "We have only yet controlled the robot with a single task (either the 3d position or the 6d placement errors). Let's see how to take into account a second task. Let's first introduce a second task. \n",
    "\n",
    "#### Introducing a second task: control the gaze\n",
    "The robot has an additional frame named F_gaze, attached to the head and located 40 cm in front of the cameras. The task will be to position (3d) the center of this frame on an object of interest (a red ball)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/control_head_robot\n",
    "robot = loadTiago(addGazeFrame=True)\n",
    "viz = MeshcatVisualizer(robot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/control_head_gaze\n",
    "IDX_GAZE = robot.model.getFrameId('framegaze')\n",
    "\n",
    "# Add a small ball as a visual target to be reached by the robot\n",
    "ball = np.array([ 1.2,0.5,1.1 ])\n",
    "viz.addSphere('ball', .05, [ .8,.1,.5, .8] )\n",
    "viz.applyConfiguration('ball', list(ball)+[0,0,0,1])\n",
    "viz.addBox('goal', [.1,.1,.1], [ .1,.1,.5, .6] )\n",
    "viz.applyConfiguration('goal',oMgoal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.display(q0)\n",
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling this point can be done by achieving a simple variation of the control law for positioning (3d) the robot tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/control_head_gaze_loop\n",
    "q = q0.copy()\n",
    "herr = [] # Log the value of the error between gaze and ball.\n",
    "# Loop on an inverse kinematics for 300 iterations.\n",
    "for i in range(300):  # Integrate over 3 second of robot life\n",
    "\n",
    "    # Run the algorithms that outputs values in robot.data\n",
    "    pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "    pin.computeJointJacobians(robot.model,robot.data,q)\n",
    "\n",
    "    # Placement from world frame o to frame f oMgaze\n",
    "    oMgaze = robot.data.oMf[IDX_GAZE]\n",
    "\n",
    "    # 6D jacobian in local frame\n",
    "    o_Jgaze3 = pin.computeFrameJacobian(robot.model, robot.data, q, IDX_GAZE,pin.LOCAL_WORLD_ALIGNED)[:3,:]\n",
    "\n",
    "    # vector from gaze to ball, in world frame\n",
    "    o_GazeBall = oMgaze.translation-ball\n",
    "    \n",
    "    vq = -pinv(o_Jgaze3) @ o_GazeBall\n",
    "\n",
    "    q = pin.integrate(robot.model,q, vq * DT)\n",
    "    viz.display(q)\n",
    "    time.sleep(1e-3)\n",
    "\n",
    "    herr.append(o_GazeBall) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing 2 tasks\n",
    "\n",
    "We now have two tasks (e1,J1) controlling the tool and (e2,J2) controlling the gaze. \n",
    "If we try to solve them concurrently, they can end up being conflicting.\n",
    "\n",
    "There is a trick that consists in solving the second task in the so-called null space \n",
    "of the first one. In our case, we want to only address the gaze task if it does not affect negatively affect \n",
    "the placement of the hand. One option to solve this issue is to ponderate the task by assigning different weights to the tasks. Another way is to try to stricly enforce the priority of one task over the other.\n",
    "\n",
    "Intuitively, we can easily understand that some joints have no effect on task 1: the 2 head dofs have no influence on the position of the hand, so we are free to modify them. However, the prismatic joint and the mobile basis, if actuated, can enter in conflict with the tool task. Still, they can be actuated in such a way that they do not perturb the achievement of the first task while helping with the second one, although it is less trivial to see it.\n",
    "\n",
    "The null space projector P of a jacobian J takes any vector $vq_k$ and projects it into a new vector such that\n",
    "$$\\nu = J v = J ( vq + P vq_k ),  \\forall vq_k$$\n",
    "\n",
    "In other words, we can change the velocity vector vq to a better suited one without modifying the effector velocity obtained (Remember that this is only true locally though, so $vq_k$ should have a small norm); \n",
    "\n",
    "The null space projector of $J_1$ can be computed using the pseudoinverse.\n",
    "Following the control law performing task 1 and task 2 in the null space of task 1 is:\n",
    "$$vq_1 = J_1^+ v_1^*$$\n",
    "$$P_1 = I_{15} - J_1^+ J_1$$\n",
    "$$vq_2 = vq_1 + (J_2 P_1)^+ ( v_2^* - J_2 vq_1)$$\n",
    "\n",
    "We can now implement a control law solving the two tasks, i.e positioning the tool while controlling the gaze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp3/generated/control_head_multi\n",
    "q = q0.copy()\n",
    "herr = [] # Log the value of the error between tool and goal.\n",
    "herr2 = [] # Log the value of the error between gaze and ball.\n",
    "# Loop on an inverse kinematics for 300 iterations.\n",
    "for i in range(300):  # Integrate over 3 second of robot life\n",
    "\n",
    "    pin.framesForwardKinematics(robot.model,robot.data,q)\n",
    "    pin.computeJointJacobians(robot.model,robot.data,q)\n",
    "\n",
    "    # Gaze task\n",
    "    oMgaze = robot.data.oMf[IDX_GAZE]\n",
    "    o_Jgaze3 = pin.computeFrameJacobian(robot.model, robot.data, q, IDX_GAZE,pin.LOCAL_WORLD_ALIGNED)[:3,:]\n",
    "    o_GazeBall = oMgaze.translation-ball\n",
    "\n",
    "    # Tool task\n",
    "    oMtool = robot.data.oMf[IDX_TOOL]\n",
    "    o_Jtool3 = pin.computeFrameJacobian(robot.model,robot.data,q,IDX_TOOL,pin.LOCAL_WORLD_ALIGNED)[:3,:]\n",
    "    o_TG = oMtool.translation-oMgoal.translation\n",
    "    \n",
    "    vq = -pinv(o_Jtool3) @ o_TG\n",
    "    Ptool = np.eye(robot.nv)-pinv(o_Jtool3) @ o_Jtool3\n",
    "    vq += pinv(o_Jgaze3 @ Ptool) @ (-o_GazeBall - o_Jgaze3 @ vq)\n",
    "\n",
    "    q = pin.integrate(robot.model,q, vq * DT)\n",
    "    viz.display(q)\n",
    "    time.sleep(1e-3)\n",
    "\n",
    "    herr.append(o_TG)\n",
    "    herr2.append(o_GazeBall) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A third task can be implemented as well by computing the null space of the two first tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pgaze = Ptool - pinv(o_Jgaze3 @ Ptool) @ o_Jgaze3 @ Ptool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional extra work\n",
    "\n",
    "I. Implement the inverse kinematics loop using a constrained optimisation library. You can use quadprod to formulate the problem and enforce joint limits as hard constraints. If for some reason you can't use quadprog you can use slsqp, although it is a bit overkill: we have seen in class that the optimisation problem we want to solve is convex, so we don't need a non-linear solver for that.\n",
    "You can also add a secondary cost that consists in computing a configuration close to the default configuration robot.q0 (ignoring the mobile base position in the cost). This is a called a postural task and is a classic way to ensure that the robot poses remain more or less natural.\n",
    "\n",
    "\n",
    "II. Load an extra cube in the viewer to figure a table. First control the robot hand to reach an arbitrary point on the table (don't mind for the collision). Then implement a control law to control three tasks:\n",
    "* the tool frame should be kept on the table (i.e. only the z component of the error matter, select only the 3rd row of the matrix).\n",
    "* the gaze should be controlled to reach the position of a ball object positionned on the table.\n",
    "* the center of the basis frame should reach a given target on the floor. For this task, only the x- and y- component of the task matter, select only the 2 first rows.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aro-tut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
